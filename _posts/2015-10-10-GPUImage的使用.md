
---
layout: post
category: GPUImage
tagline: "Supporting tagline"
tags: \[GPUImage]
---

##总体架构##

GPUImage使用OpenGL ES 2.0着色器来执行图像和视频处理速度远远超过可以在中央处理器受限完成例程。然而,它隐藏了复杂性与OpenGL ES API进行交互的一个简化的objective - c接口。这个接口允许您定义为图片和视频输入源,附加过滤器链,并将结果处理图像或视频屏幕,用户界面图像,或磁盘上的电影.

图像或帧的视频从源对象上传,他是GPUImageOutput的子类。这些包括GPUImageVideoCamera(视频从一个iOS相机),GPUImageStillCamera(拍照相机),GPUImagePicture(图片),和GPUImageMovie(电影)。源对象仍然上传图像帧OpenGL ES纹理,然后手这些纹理处理链中的下一个对象。

过滤器链中的和其他后续元素符合GPUImageInput协议,这让他们在提供的或加工纹理从以前的环节和做一些事情。对象进一步沿着链被认为是目标,可以通过添加多个目标分支和处理一个单一的输出或过滤器。

例如,一个应用程序,该应用程序需要在视频直播的相机,将视频转换成深褐色的语气,然后屏幕上显示视频会建立一个链看起来像下面这样:

GPUImageVideoCamera -> GPUImageSepiaFilter -> GPUImageView


##在项目中添加GPU##

　　注意:如果您想要使用这在迅速项目中,您需要使用的步骤在“添加这个框架”部分,而不是追随者。斯威夫特需要第三方代码模块.
　　　　

　　一旦你有最新的源代码框架,这是　　相当简单的将它添加到您的应用程序。通过　　拖动GPUImage开始。xcodeproj文件到您的应用程序中嵌入一Xcode项目框架在您的项目中。接下来,去您的应用程序的目标并添加GPUImage作为目标的依赖。最后,你需要拖动  lib  GPUImage。library 从GPUImage框架的产品文件夹链接的二进制库在应用程序中构建阶段的目标。　　

　　GPUImage需要其他一些框架连接到您的应用程序,所以你需要在应用程序中添加以下链接库目标:　　

* CoreMedia
* CoreVideo
* OpenGLES
* AVFoundation
* QuartzCore


....下面又说了一堆其他的方式 [链接](https://github.com/BradLarson/GPUImage)

##文档##

生成文档的标题使用appledoc。建立文档,切换到“文档”计划在Xcode中。你应该确保“APPLEDOC_PATH”(一个用户定义的构建设置)指向一个appledoc二进制,可在Github或通过自制程序。它还将建造和安装。docset文件,你可以把你喜欢的文档工具。(就是说使用appledoc 生成文档, 这个是无关紧要的,如果你会使用appdoc)

##执行常见任务##

###视频直播的滤镜###
    
过滤一个从iOS设备获取的视频,你可以使用代码如下:
　　   
    
    GPUImageVideoCamera *videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:AVCaptureSessionPreset640x480 cameraPosition:AVCaptureDevicePositionBack];
    
	videoCamera.outputImageOrientation = UIInterfaceOrientationPortrait;

	GPUImageFilter *customFilter = [[GPUImageFilter alloc] initWithFragmentShaderFromFile:@"CustomShader"];
	
	GPUImageView *filteredVideoView = [[GPUImageView alloc] initWithFrame:CGRectMake(0.0, 0.0, viewWidth, viewHeight)];

	// Add the view somewhere so it's visible

	[videoCamera addTarget:customFilter];
	[customFilter addTarget:filteredVideoView];
	[videoCamera startCameraCapture];
　　
　　这形成了一种来自于iOS设备的后面的摄像头的视频源,使用一个预设试图捕捉在640 x480。这个视频捕获接口是在肖像模式下,在landscape-left-mounted相机之前需要有其视频帧旋转展示。一个自定义的过滤器,CustomShader使用代码的文件。fsh,然后设置为从相机视频帧的目标。这些过滤视频帧的帮助下终于在屏幕上显示一个UIView子类可以过滤OpenGL ES纹理,结果从这个管道输出。
　　
　　GPUImageView的填充模式可以改变通过设置fillMode产权,如果源视频的长宽比是不同的观点,视频会被拉伸,以黑色的框框,或放大来填补。
　　
　　为混合过滤器和其他在多个图像,您可以创建多个输出并且添加一个过滤器作为这两个目标的输出。添加的顺序输出作为目标将影响的顺序输入图像混合或以其他方式处理。
　　	
　　	同样,如果你想使麦克风音频捕捉记录电影的生硬,你需要将相机的audioEncodingTarget设置为 movieWriter ,如下列:
    
    videoCamera.audioEncodingTarget = movieWriter;


###捕捉并过滤静止的图片###

捕获和过滤静止的照片,您类似与过滤视频的过程。不过不是GPUImageVideoCamera,你得使用  ```GPUImageStillCamera:```
    
    stillCamera = [[GPUImageStillCamera alloc] init];
	stillCamera.outputImageOrientation = UIInterfaceOrientationPortrait;

	filter = [[GPUImageGammaFilter alloc] init];
	[stillCamera addTarget:filter];
	GPUImageView *filterView = (GPUImageView *)self.view;
	[filter addTarget:filterView];

	[stillCamera startCameraCapture];

　　
这将给你一个生活、过滤提要的相机预览视频。注意,这个预览视频只是提供iOS 4.3和更高版本,所以你可能需要设置您的部署目标如果你想拥有此功能。

一旦你想捕捉一个照片,你使用一个回调块如下:

    
    [stillCamera capturePhotoProcessedUpToFilter:filter withCompletionHandler:^(UIImage *processedImage, NSError *error){
    NSData *dataForJPEGFile = UIImageJPEGRepresentation(processedImage, 0.8);

    NSArray *paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);
    NSString *documentsDirectory = [paths objectAtIndex:0];

    NSError *error2 = nil;
    if (![dataForJPEGFile writeToFile:[documentsDirectory stringByAppendingPathComponent:@"FilteredPhoto.jpg"] options:NSAtomicWrite error:&error2])
    {
        return;
    }
	}];
　　
　　
上面的代码捕获一个全尺寸照片处理中使用的相同的过滤器链预览视图并将照片保存到磁盘作为应用程序的JPEG文件目录。
























　　