
---
layout: post
category: GPUImage
tagline: "Supporting tagline"
tags: [GPUImage]
---

## 总体架构 #\#

GPUImage使用OpenGL ES 2.0着色器来执行图像和视频处理速度远远超过可以在中央处理器受限完成例程。然而,它隐藏了复杂性与OpenGL ES API进行交互的一个简化的objective - c接口。这个接口允许您定义为图片和视频输入源,附加过滤器链,并将结果处理图像或视频屏幕,用户界面图像,或磁盘上的电影.

图像或帧的视频从源对象上传,他是GPUImageOutput的子类。这些包括GPUImageVideoCamera(视频从一个iOS相机),GPUImageStillCamera(拍照相机),GPUImagePicture(图片),和GPUImageMovie(电影)。源对象仍然上传图像帧OpenGL ES纹理,然后手这些纹理处理链中的下一个对象。

过滤器链中的和其他后续元素符合GPUImageInput协议,这让他们在提供的或加工纹理从以前的环节和做一些事情。对象进一步沿着链被认为是目标,可以通过添加多个目标分支和处理一个单一的输出或过滤器。

例如,一个应用程序,该应用程序需要在视频直播的相机,将视频转换成深褐色的语气,然后屏幕上显示视频会建立一个链看起来像下面这样:

GPUImageVideoCamera -\> GPUImageSepiaFilter -\> GPUImageView


## 在项目中添加GPU

　　注意:如果您想要使用这在迅速项目中,您需要使用的步骤在“添加这个框架”部分,而不是追随者。斯威夫特需要第三方代码模块.
　　　　

　　一旦你有最新的源代码框架,这是　　相当简单的将它添加到您的应用程序。通过　　拖动GPUImage开始。xcodeproj文件到您的应用程序中嵌入一Xcode项目框架在您的项目中。接下来,去您的应用程序的目标并添加GPUImage作为目标的依赖。最后,你需要拖动  lib  GPUImage。library 从GPUImage框架的产品文件夹链接的二进制库在应用程序中构建阶段的目标。　　

　　GPUImage需要其他一些框架连接到您的应用程序,所以你需要在应用程序中添加以下链接库目标:　　

* CoreMedia
* CoreVideo
* OpenGLES
* AVFoundation
* QuartzCore


....下面又说了一堆其他的方式 [链接][1]

## 文档

生成文档的标题使用appledoc。建立文档,切换到“文档”计划在Xcode中。你应该确保“APPLEDOC\_PATH”(一个用户定义的构建设置)指向一个appledoc二进制,可在Github或通过自制程序。它还将建造和安装。docset文件,你可以把你喜欢的文档工具。(就是说使用appledoc 生成文档, 这个是无关紧要的,如果你会使用appdoc)

## 执行常见任务 

### 视频直播的滤镜
过滤一个从iOS设备获取的视频,你可以使用代码如下:
　　   
	GPUImageVideoCamera *videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:AVCaptureSessionPreset640x480 cameraPosition:AVCaptureDevicePositionBack];
	
	videoCamera.outputImageOrientation = UIInterfaceOrientationPortrait;
	
	GPUImageFilter *customFilter = [[GPUImageFilter alloc] initWithFragmentShaderFromFile:@"CustomShader"];
	
	GPUImageView *filteredVideoView = [[GPUImageView alloc] initWithFrame:CGRectMake(0.0, 0.0, viewWidth, viewHeight)];
	
	// Add the view somewhere so it's visible
	
	[videoCamera addTarget:customFilter];
	[customFilter addTarget:filteredVideoView];
	[videoCamera startCameraCapture];
　　
　　这形成了一种来自于iOS设备的后面的摄像头的视频源,使用一个预设试图捕捉在640 x480。这个视频捕获接口是在肖像模式下,在landscape-left-mounted相机之前需要有其视频帧旋转展示。一个自定义的过滤器,CustomShader使用代码的文件。fsh,然后设置为从相机视频帧的目标。这些过滤视频帧的帮助下终于在屏幕上显示一个UIView子类可以过滤OpenGL ES纹理,结果从这个管道输出。
　　
　　GPUImageView的填充模式可以改变通过设置fillMode产权,如果源视频的长宽比是不同的观点,视频会被拉伸,以黑色的框框,或放大来填补。
　　
　　为混合过滤器和其他在多个图像,您可以创建多个输出并且添加一个过滤器作为这两个目标的输出。添加的顺序输出作为目标将影响的顺序输入图像混合或以其他方式处理。
　　   
　　  同样,如果你想使麦克风音频捕捉记录电影的生硬,你需要将相机的audioEncodingTarget设置为 movieWriter ,如下列:
	videoCamera.audioEncodingTarget = movieWriter;


### 捕捉并过滤静止的图片

捕获和过滤静止的照片,您类似与过滤视频的过程。不过不是GPUImageVideoCamera,你得使用  `GPUImageStillCamera:`
	stillCamera = [[GPUImageStillCamera alloc] init];
	stillCamera.outputImageOrientation = UIInterfaceOrientationPortrait;
	
	filter = [[GPUImageGammaFilter alloc] init];
	[stillCamera addTarget:filter];
	GPUImageView *filterView = (GPUImageView *)self.view;
	[filter addTarget:filterView];
	
	[stillCamera startCameraCapture];

　　
这将给你一个生活、过滤提要的相机预览视频。注意,这个预览视频只是提供iOS 4.3和更高版本,所以你可能需要设置您的部署目标如果你想拥有此功能。

一旦你想捕捉一个照片,你使用一个回调块如下:

	[stillCamera capturePhotoProcessedUpToFilter:filter withCompletionHandler:^(UIImage *processedImage, NSError *error){
	NSData *dataForJPEGFile = UIImageJPEGRepresentation(processedImage, 0.8);
	
	NSArray *paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);
	NSString *documentsDirectory = [paths objectAtIndex:0];
	
	NSError *error2 = nil;
	if (![dataForJPEGFile writeToFile:[documentsDirectory stringByAppendingPathComponent:@"FilteredPhoto.jpg"] options:NSAtomicWrite error:&error2])
	{
	    return;
	}
	}];
　　
　　
上面的代码捕获一个全尺寸照片处理中使用的相同的过滤器链预览视图并将照片保存到磁盘作为应用程序的JPEG文件目录。

注意,该框架目前无法处理图像大于2048像素宽或高老设备上(这些在iPhone 4 s,iPad 2,或视网膜iPad)由于纹理尺寸限制。这意味着iPhone 4的相机输出仍然大于这个照片,无法捕捉这样的照片。瓷砖机制实施工作。所有其他设备应该能够捕获和过滤照片使用这种方法。

### 加工一个静态的图片

加工一个静态的图片的方式是多样的.第一种方式是你创建图片和过滤链.

	UIImage *inputImage = [UIImage imageNamed:@"Lambeau.jpg"]
	
	GPUImagePicture *stillImageSource = [[GPUImagePicture alloc] initWithImage:inputImage];
	GPUImageSepiaFilter *stillImageFilter = [[GPUImageSepiaFilter alloc] init];
	
	[stillImageSource addTarget:stillImageFilter];
	[stillImageFilter useNextFrameForImageCapture];
	[stillImageSource processImage];
	
	UIImage *currentFilteredVideoFrame = [stillImageFilter imageFromCurrentFramebuffer];

注意从一个过滤器获取人工捕捉的图像,您需要设置-useNextFrameForImageCapture为了告诉你们需要捕捉的过滤器。默认情况下,GPUImage重用framebuffer过滤器内节约内存,所以如果你需要抓住一个过滤器的framebuffer手动图像捕获,你需要让它提前知道。

针对单一过滤器,您希望应用到一个图像,只需执行以下操作:

	GPUImageSepiaFilter *stillImageFilter2 = [[GPUImageSepiaFilter alloc] init];
	UIImage *quickFilteredImage = [stillImageFilter2 imageByFilteringImage:inputImage];

### 写一个自定义的过滤器

这个框架比coreimage 牛B的一个重要的地方,是能够编写自己的自定义图像和视频处理过滤器。这些过滤器是OpenGL ES 2.0提供片段着色器,用c编写的OpenGL着色语言。

自定义过滤器初始化代码

	GPUImageFilter *customFilter = [[GPUImageFilter alloc] initWithFragmentShaderFromFile:@"CustomShader"];

在扩展用于.fsh片段着色器。此外,您可以使用`-initWithFragmentShaderFromString:`初始化提供片段着色器作为一个字符串,如果你不愿意装运你的片段着色器在您的应用程序包。

片段着色器执行他们的计算为每个像素呈现在过滤阶段。他们这么做使用OpenGL着色语言(GLSL),c语言与添加特定于2 d和3 d图形。下面是片段着色器的一个例子:


varying highp vec2 textureCoordinate;

uniform sampler2D inputImageTexture;

	void main()
	{
	lowp vec4 textureColor = texture2D(inputImageTexture, textureCoordinate);
	lowp vec4 outputColor;
	outputColor.r = (textureColor.r * 0.393) + (textureColor.g * 0.769) + (textureColor.b * 0.189);
	outputColor.g = (textureColor.r * 0.349) + (textureColor.g * 0.686) + (textureColor.b * 0.168);    
	outputColor.b = (textureColor.r * 0.272) + (textureColor.g * 0.534) + (textureColor.b * 0.131);
	outputColor.a = 1.0;
	
	gl_FragColor = outputColor;
	}


为一个图像滤波器可用GPUImage框架内,textureCoordinate不同的前两行,(当前纹理坐标,归一化到1.0)和inputImageTexture制服(实际输入图像帧结构)是必需的。

剩下的材质抓住像素的颜色在这个位置传入纹理,操纵它以这样一种方式生产深褐色的语气,和写像素颜色是用于处理管道的下一个阶段。
一件事要注意当片段着色器添加到你的Xcode项目是Xcode认为他们是源代码文件。为了解决这一问题,您将需要手动移动你的着色器的编译源构建阶段复制包资源为了得到材质被包括在您的应用程序包。


### 过滤和重新编码的电影 
wow 到重点了 🐱 

电影可以通过GPUImageMovie类加载到框架,使用GPUImageMovieWriter过滤,然后写出。GPUImageMovieWriter也足够快的录制视频实时从iPhone 4在640 x480的相机,所以直接过滤可以输入视频源。目前,GPUImageMovieWriter足够快来记录生活720 p视频在20 FPS iPhone 4,720 p和1080 p视频在iPhone 4 s 30 FPS(以及新的iPad)

下面是一个例子,如何加载一个样本的movie,通过一个pixellation过滤器,然后记录结果到磁盘作为480 x 640 h。264年的movie:

	movieFile = [[GPUImageMovie alloc] initWithURL:sampleURL];
	pixellateFilter = [[GPUImagePixellateFilter alloc] init];
	
	[movieFile addTarget:pixellateFilter];
	
	NSString *pathToMovie = [NSHomeDirectory() stringByAppendingPathComponent:@"Documents/Movie.m4v"];
	unlink([pathToMovie UTF8String]);
	NSURL *movieURL = [NSURL fileURLWithPath:pathToMovie];
	
	movieWriter = [[GPUImageMovieWriter alloc] initWithMovieURL:movieURL size:CGSizeMake(480.0, 640.0)];
	[pixellateFilter addTarget:movieWriter];
	
	movieWriter.shouldPassthroughAudio = YES;
	movieFile.audioEncodingTarget = movieWriter;
	[movieFile enableSynchronizedEncodingUsingMovieWriter:movieWriter];
	
	[movieWriter startRecording];
	[movieFile startProcessing];

录音完成后,您需要删除过滤器链的电影记录器和关闭录音使用代码如下:

	[pixellateFilter removeTarget:movieWriter];
	[movieWriter finishRecording];

电影不会是可用的,直到它已经完成了,所以如果这是打断这一点之前,录音将丢失

### Interacting with OpenGL ES

　　从OpenGL ES PUImage既可以导出和导入纹理通过使用其GPUImageTextureOutput和GPUImageTextureInput类,分别。这允许您记录电影从一个OpenGL ES场景呈现framebuffer对象绑定纹理,或者过滤视频或图片,然后给他们到OpenGL ES纹理显示在现场。
　　
　　的使用这种方法有一点需要注意的是,这些过程中使用的纹理必须共享GPUImage OpenGL ES之间的上下文和其他上下文通过共享集团或类似的东西。

### 内置的过滤器
目前有125内置过滤器,分为以下类别:
　 
## Color adjustments (颜色处理)
　
呱呱呱说了一堆

### Image processing (图像处理)

呱呱呱说了一堆

### Blending modes (混合模式)

呱呱呱说了一堆

### Visual effects(视觉特效)

呱呱呱又说了一堆


## 一些例子

前方高能预警

….

..
..
.




下面是对例子的一些说明可能是最棒的部分了

..end 撒花

[1]:	https://github.com/BradLarson/GPUImage